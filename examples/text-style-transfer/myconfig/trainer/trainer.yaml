# train_params:
max_steps: -1

# eval_params:
do_eval: true
steps: -1

# save_params:
do_save: true
dir: './outputs'

# optimizer_params:
# learning_rate: 0.0001
gradient_clip: true
gradient_clip_norm: 5.0

# checkpoint_params:
path: null

random_seed: null

# wandb_reporting:
project_name: 'rl-prompt'
run_name: null


# lzy
debug_off: false
mixed_precision: bf16
only_compute_for_gt0_when_off: false
batch_size: 2
num_epochs: 100
log_with: wandb
learning_rate: 1e-4
reward_multiply: 1

# if you use deepspeed, pls set grad_clipping to your number
max_grad_norm: 5.0

ref_update_method: polyak
ref_learning_rate:  0.001
sql_loss_impl: v2_v2r_v3_v3r
training_mode: sql-onpolicy
# sql-mixed
  # mix
  # alternate

# sql-onpolicy
# sql-offpolicy
mix_strategy: alternate
margin_constant: null
margin_coefficient: null
base_root: /home/liao.629/rl-prompt-lzy/examples/text-style-transfer
save_dir: ckpt
s_p_t_dir: /home/liao.629/rl-prompt-lzy/examples/text-style-transfer/s_p_t
